{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ledmaster/TutorialEnsemble/blob/master/HomePrices.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from itertools import product\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('datasets/train.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train.drop('SalePrice', axis=1), train.SalePrice.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funçoes para calculo do erro\n",
    "\n",
    "def rmsle(estimator, x, y):\n",
    "    p = estimator.predict(x)\n",
    "    return np.sqrt(mean_squared_error(np.log1p(y), np.log1p(p)))\n",
    "\n",
    "def rmsle_log_y(estimator, x, y):\n",
    "    p = estimator.predict(x)\n",
    "    return np.sqrt(mean_squared_error(y,p))\n",
    "\n",
    "def rmsle_sqrt_y(estimator, x, y):\n",
    "    p = estimator.predict(x)\n",
    "    y = np.power(y,2)\n",
    "    p = np.power(p,2)\n",
    "    return np.sqrt(mean_squared_error(np.log1p(y), np.log1p(p)))\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dims (1460, 36)\n",
      "RMSLE:  0.14582352617986846\n"
     ]
    }
   ],
   "source": [
    "x1 = x.select_dtypes(include=[np.number]).fillna(-1)\n",
    "print('Dims', x1.shape)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=1000, random_state=0)\n",
    "error = cross_val_score(model, x1, y, cv=kf, scoring=rmsle)\n",
    "print('RMSLE: ', np.mean(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set 2: Ordinal Encoding Categóricas  \n",
    "Agora vamos criar um outro conjunto de features, desta vez adicionando as variáveis categóricas. Existem várias maneiras de codificar este tipo de variável para os modelos, uma delas é usando um formato ordinal. Isso simplesmente significa substituir cada valor original por números sequenciais. Em alguns modelos isso pode ser problemático, pois eles tentarão capturar alguma relação de ordem em valores que podem não ter. No nosso caso, com modelos baseados em árvores de decisão, este problema é quase inexistente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dims (1460, 79)\n",
      "RMSLE:  0.14383736485915208\n"
     ]
    }
   ],
   "source": [
    "x2 = x.copy()\n",
    "\n",
    "for col in x2.columns:\n",
    "    if x2[col].dtype == object:\n",
    "        enc = LabelEncoder()\n",
    "        x2[col] = enc.fit_transform(x[col].fillna('Missing'))\n",
    "\n",
    "print('Dims', x2.shape)\n",
    "x2.fillna(-1, inplace=True)\n",
    "model = RandomForestRegressor(n_estimators=1000, random_state=0)\n",
    "error = cross_val_score(model, x2, y, cv=kf, scoring=rmsle).mean()\n",
    "print('RMSLE: ',error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformações do Target\n",
    "Uma maneira interessante de criar diversidade, e às vezes até obter uma melhor performance, num caso de regressão, é transformar a variável que estamos tentando prever. Neste caso testaremos duas transformações: logaritmo e raiz quadrada.\n",
    "\n",
    "### Log\n",
    "É possível ver que tentar prever o logaritmo do preço nos dá um resultado melhor. Isto acontece não só pelo fato do modelo capturar padrões diferentes, mas também porque usamos uma métrica baseada na diferença de logaritmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, x1, log-target RMSLE:  0.14516215148522235\n",
      "RF, x2, log-target RMSLE:  0.14213588563678017\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=1000, random_state=0)\n",
    "error = cross_val_score(model, x1, np.log1p(y), cv=kf, scoring=rmsle_log_y).mean()\n",
    "print('RF, x1, log-target RMSLE: ', error)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=1000, random_state=0)\n",
    "error = cross_val_score(model, x2, np.log1p(y), cv=kf, scoring=rmsle_log_y).mean()\n",
    "print('RF, x2, log-target RMSLE: ', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raiz Quadrada\n",
    "Esta transformação também nos dá um resultado melhor do que usar a variável em seu estado original. Uma das sugestões da razão pela qual vemos este efeito é que estas transformações fazem com que a variável y tenha uma distribuição mais próxima da normal, o que facilita o trabalho do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF, x1, log-target RMSLE:  0.14565293448427202\n",
      "RF, x2, log-target RMSLE:  0.14300460013198157\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=1000, random_state=0)\n",
    "error = cross_val_score(model, x1, np.sqrt(y), cv=kf, scoring=rmsle_sqrt_y).mean()\n",
    "print('RF, x1, log-target RMSLE: ', error)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=1000, random_state=0)\n",
    "error = cross_val_score(model, x2, np.sqrt(y), cv=kf, scoring=rmsle_sqrt_y).mean()\n",
    "print('RF, x2, log-target RMSLE: ', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerando modelos com modelos/algoritmos diferentes\n",
    "Outra maneira de gerar diversidade para o ensemble é gerar modelos diferentes. Neste caso vou usar meu modelo preferido, o GBM. Este também é baseado em árvores de decisão, mas basicamente treina cada árvore sequencialmente focando nos erros cometidos pelas anteriores.\n",
    "\n",
    "Nas células abaixo é possível ver a performance deste modelo nos feature sets e transformações que usamos com a Random Forest. Vemos que ele traz uma melhora significativa, capturando melhor os padrões da relação entre as variáveis e o preço de venda dos imóveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM, x1, log-target RMSLE:  0.1334924549135666\n",
      "GBM, x1, log-target RMSLE:  0.12980689048155078\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(random_state=0)\n",
    "error = cross_val_score(model, x1, np.log1p(y), cv=kf, scoring=rmsle_log_y).mean()\n",
    "print('GBM, x1, log-target RMSLE: ', error)\n",
    "\n",
    "model = GradientBoostingRegressor(random_state=0)\n",
    "error = cross_val_score(model, x2, np.log1p(y), cv=kf, scoring=rmsle_log_y).mean()\n",
    "print('GBM, x1, log-target RMSLE: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM, X1, sqrt-target RMSLE: 0.13425897281342522\n",
      "GBM, X2, sqrt-target RMSLE: 0.1309192356821107\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(random_state=0)\n",
    "error = cross_val_score(model, x1, np.sqrt(y), cv=kf, scoring=rmsle_sqrt_y).mean()\n",
    "print('GBM, X1, sqrt-target RMSLE:', error)\n",
    "\n",
    "model = GradientBoostingRegressor(random_state=0)\n",
    "error = cross_val_score(model, x2, np.sqrt(y), cv=kf, scoring=rmsle_sqrt_y).mean()\n",
    "print('GBM, X2, sqrt-target RMSLE:', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking\n",
    "\n",
    "O Stacking é uma maneira de fazer o ensemble na qual usamos modelos para fazer previsões, e depois usamos estas previsões como features em novos modelos, no que pode ser chamado de \"segundo nível\". Você pode fazer este processo várias vezes, mas a cada nível o retorno em performance com relação à computação necessária é menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE Fold 0 - RSLE 0.1250\n",
      "RMSLE Fold 1 - RSLE 0.1446\n",
      "RMSLE Fold 2 - RSLE 0.1253\n",
      "RMSLE Fold 3 - RSLE 0.1387\n",
      "RMSLE Fold 4 - RSLE 0.1086\n",
      "RMSL CV5 0.1284\n"
     ]
    }
   ],
   "source": [
    "kf_out = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "kf_in = KFold(n_splits=5, shuffle=True, random_state=2)\n",
    "\n",
    "cv_mean = []\n",
    "for fold, (tr, ts) in enumerate(kf_out.split(x,y)):\n",
    "    x1_train, x1_test = x1.iloc[tr], x1.iloc[ts]\n",
    "    x2_train, x2_test = x2.iloc[tr], x2.iloc[ts]\n",
    "    y_train, y_test = y.iloc[tr], y.iloc[ts]\n",
    "    \n",
    "    modelos = [GradientBoostingRegressor(random_state=0), RandomForestRegressor(random_state=0)]\n",
    "    targets = [np.log1p, np.sqrt]\n",
    "    feature_sets = [(x1_train, x1_test), (x2_train, x2_test)]\n",
    "    \n",
    "    predictions_cv = []\n",
    "    predictions_test = []\n",
    "    for model, target, feature_set in product(modelos, targets, feature_sets):\n",
    "        predictions_cv.append(cross_val_predict(model, feature_set[0], target(y_train), \n",
    "                                                cv=kf_in).reshape(-1,1))\n",
    "        model.fit(feature_set[0], target(y_train))\n",
    "        ptest = model.predict(feature_set[1])\n",
    "        predictions_test.append(ptest.reshape(-1,1))\n",
    "        \n",
    "    predictions_cv = np.concatenate(predictions_cv, axis=1)\n",
    "    predictions_test = np.concatenate(predictions_test, axis=1)\n",
    "    \n",
    "    stacker = Ridge()\n",
    "    stacker.fit(predictions_cv, np.log1p(y_train))\n",
    "    error = rmsle_log_y(stacker, predictions_test, np.log1p(y_test))\n",
    "    cv_mean.append(error)\n",
    "    print('RMSLE Fold %d - RSLE %.4f' % (fold, error))\n",
    "\n",
    "print(\"RMSL CV5 %.4f\" % np.mean(cv_mean))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
